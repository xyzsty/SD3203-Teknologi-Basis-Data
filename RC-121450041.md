# Three Ways of Storing and Accessing Lots of Images in Python



```python
import numpy as np
import pickle
from pathlib import Path

# Path to the unzipped CIFAR data
data_dir = Path("/content/cifar-10-batches-py")

# Unpickle function provided by the CIFAR hosts
def unpickle(file):
    with open(file, "rb") as fo:
        dict = pickle.load(fo, encoding="bytes")
    return dict

images, labels = [], []
for batch in data_dir.glob("data_batch_*"):
    batch_data = unpickle(batch)
    for i, flat_im in enumerate(batch_data[b"data"]):
        im_channels = []
        # Each image is flattened, with channels in order of R, G, B
        for j in range(3):
            im_channels.append(
                flat_im[j * 1024 : (j + 1) * 1024].reshape((32, 32))
            )
        # Reconstruct the original image
        images.append(np.dstack((im_channels)))
        # Save the label
        labels.append(batch_data[b"labels"][i])

print("Loaded CIFAR-10 training set:")
print(f" - np.shape(images)     {np.shape(images)}")
print(f" - np.shape(labels)     {np.shape(labels)}")
```

    Loaded CIFAR-10 training set:
     - np.shape(images)     (50000, 32, 32, 3)
     - np.shape(labels)     (50000,)
    

Kode tersebut memuat dataset CIFAR-10 dari file-file batch yang telah diproses sebelumnya. Setiap batch diambil dari direktori yang ditentukan menggunakan `Path`, kemudian setiap gambar dalam batch diproses. Setiap gambar diubah dari format yang dipampatkan menjadi struktur data yang sesuai, dengan saluran warna dalam urutan merah, hijau, dan biru, dan kemudian direkonstruksi menjadi gambar asli.

Setelah itu, gambar-gambar dan label-labelnya dimasukkan ke dalam list terpisah. Dimensi dari gambar-gambar dan label-label tersebut ditampilkan dengan menggunakan `np.shape`, dan pesan yang memberitahu bahwa dataset CIFAR-10 telah dimuat juga ditampilkan.

## Melakukan pengaturan untuk menyimpan gamabr di disk

menginstal paket Pillow


```python
pip install Pillow
```

    Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)
    

## Memulai dengan LMDB

Database yang dipetakan langsung ke memori (LMDB) adalah penyimpanan nilai kunci yang cepat dan menggunakan file yang dipetakan memori. Ini berbeda dari database relasional karena menggunakan struktur pohon B+ di mana setiap elemen nilai kunci adalah simpul yang terhubung. Keunggulan lain LMDB adalah bahwa itu dapat mengatur komponen kunci pohon B+ agar sesuai dengan ukuran halaman sistem operasi, yang membuat akses ke pasangan nilai kunci lebih mudah. Selain itu, LMDB dipetakan langsung ke mem





```python
pip install lmdb
```

    Requirement already satisfied: lmdb in /usr/local/lib/python3.10/dist-packages (1.4.1)
    

## Memulai dengan HDF5

Format data hierarki HDF5 adalah format file yang disebut HDF4 atau HDF5, dengan HDF5 yang paling umum digunakan. National Center for Supercomputing Applications mengembangkan format untuk data ilmiah yang mudah dibawa. File HDF terdiri dari dua jenis objek: kumpulan data, yang terdiri dari array multidimensi, dan grup, yang dapat berisi kumpulan data atau grup lainnya. Kumpulan data dapat menyimpan array multidimensi dengan berbagai ukuran dan tipe, tetapi setiap kumpulan data harus sama dalam hal dimensi dan tipe.



```python
pip install h5py
```

    Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)
    Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.25.2)
    

# Meniympan 1 gambar

Kode tersebut menggunakan modul `Path` dari library `pathlib` untuk membuat tiga objek jalur yang mewakili direktori: `disk_dir`, `lmdb_dir`, dan `hdf5_dir`, masing-masing menunjukkan ke direktori "data/disk/", "data/lmdb/", dan "data/hdf5/".


```python
from pathlib import Path

disk_dir = Path("data/disk/")
lmdb_dir = Path("data/lmdb/")
hdf5_dir = Path("data/hdf5/")
```


```python
disk_dir.mkdir(parents=True, exist_ok=True)
lmdb_dir.mkdir(parents=True, exist_ok=True)
hdf5_dir.mkdir(parents=True, exist_ok=True)
```

## Menyimpan ke disk


```python
from PIL import Image
import csv

def store_single_disk(image, image_id, label):
    """ Stores a single image as a .png file on disk.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    Image.fromarray(image).save(disk_dir / f"{image_id}.png")

    with open(disk_dir / f"{image_id}.csv", "wt") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        writer.writerow([label])
```

Fungsi `store_single_disk` digunakan untuk menyimpan sebuah gambar dalam format .png dan labelnya dalam format .csv di dalam direktori yang telah ditentukan sebelumnya. Itu menerima tiga parameter: `image`, yang merupakan array gambar dengan ukuran (32, 32, 3), `image_id` yang merupakan ID unik untuk gambar, dan `label` yang merupakan label gambar.

## Menyimpan ke LMDB


```python
class CIFAR_Image:
    def __init__(self, image, label):
        # Dimensions of image for reconstruction - not really necessary
        # for this dataset, but some datasets may include images of
        # varying sizes
        self.channels = image.shape[2]
        self.size = image.shape[:2]

        self.image = image.tobytes()
        self.label = label

    def get_image(self):
        """ Returns the image as a numpy array. """
        image = np.frombuffer(self.image, dtype=np.uint8)
        return image.reshape(*self.size, self.channels)
```

Kelas `CIFAR_Image` digunakan untuk merepresentasikan satu gambar CIFAR-10. Dalam metode `__init__`, konstruktor menerima `image` (array gambar) dan `label` (label gambar). Properti `channels` dan `size` disetel sesuai dengan dimensi gambar. Gambar diubah menjadi byte dan disimpan dalam properti `image`, sedangkan label disimpan dalam properti `label`.

Metode `get_image` digunakan untuk mendapatkan kembali gambar dalam format array numpy. Byte dari properti `image` diubah kembali menjadi array numpy menggunakan `np.frombuffer`, kemudian diubah bentuk menjadi sesuai dengan ukuran dan saluran gambar menggunakan informasi yang tersimpan di properti `size` dan `channels`.


```python
import lmdb
import pickle

def store_single_lmdb(image, image_id, label):
    """ Stores a single image to a LMDB.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    map_size = image.nbytes * 1024

    # Create a new LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), map_size=map_size)

    # Start a new write transaction
    with env.begin(write=True) as txn:
        # All key-value pairs need to be strings
        value = CIFAR_Image(image, label)
        key = f"{image_id:08}"
        txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()
```

Fungsi `store_single_lmdb` digunakan untuk menyimpan satu gambar CIFAR-10 ke dalam sebuah basis data LMDB. Fungsi ini menerima tiga parameter: `image` (array gambar), `image_id` (ID unik untuk gambar), dan `label` (label gambar).

Ukuran peta yang digunakan dalam basis data LMDB dihitung dengan mengalikan jumlah byte dari gambar dengan 1024. Kemudian, sebuah lingkungan LMDB baru dibuat menggunakan `lmdb.open`, dengan ukuran peta yang telah dihitung sebelumnya.

Transaksi tulis baru dimulai dengan menggunakan `env.begin(write=True)`. Setiap pasangan kunci-nilai harus dalam bentuk string, jadi objek `CIFAR_Image` dibuat dengan menggunakan gambar dan label, dan kemudian disimpan dalam basis data LMDB menggunakan `txn.put`.

Akhirnya, lingkungan LMDB ditutup dengan menggunakan `env.close()`.

## Menyimpan dengan HDF5



```python
import h5py

def store_single_hdf5(image, image_id, label):
    """ Stores a single image to an HDF5 file.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "image", np.shape(image), h5py.h5t.STD_U8BE, data=image
    )
    meta_set = file.create_dataset(
        "meta", np.shape(label), h5py.h5t.STD_U8BE, data=label
    )
    file.close()
```

Fungsi `store_single_hdf5` digunakan untuk menyimpan satu gambar CIFAR-10 ke dalam sebuah file HDF5. Fungsi ini menerima tiga parameter: `image` (array gambar), `image_id` (ID unik untuk gambar), dan `label` (label gambar).

Pertama-tama, file HDF5 baru dibuat menggunakan `h5py.File` dengan nama file yang sesuai dengan ID gambar.

Selanjutnya, sebuah dataset dibuat di dalam file menggunakan `create_dataset`. Dataset ini disebut "image" dan mengandung data gambar. Metadata, yang merupakan label gambar, juga disimpan dalam dataset "meta".

Terakhir, file HDF5 ditutup menggunakan `file.close()`.

## Eksperimen untuk menyimpan 1 gambar



```python
_store_single_funcs = dict(
    disk=store_single_disk, lmdb=store_single_lmdb, hdf5=store_single_hdf5
)
```


```python
from timeit import timeit

store_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_store_single_funcs[method](image, 0, label)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    store_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```

    Method: disk, Time usage: 0.0015726900001027388
    Method: lmdb, Time usage: 0.007017041999461071
    Method: hdf5, Time usage: 0.0071217879994947
    

# Menyimpan banyak gambar



```python
def store_many_disk(images, labels):
    """ Stores an array of images to disk
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Save all the images one by one
    for i, image in enumerate(images):
        Image.fromarray(image).save(disk_dir / f"{i}.png")

    # Save all the labels to the csv file
    with open(disk_dir / f"{num_images}.csv", "w") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for label in labels:
            # This typically would be more than just one value per row
            writer.writerow([label])

def store_many_lmdb(images, labels):
    """ Stores an array of images to LMDB.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    map_size = num_images * images[0].nbytes * 10

    # Create a new LMDB DB for all the images
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), map_size=map_size)

    # Same as before â€” but let's write all the images in a single transaction
    with env.begin(write=True) as txn:
        for i in range(num_images):
            # All key-value pairs need to be Strings
            value = CIFAR_Image(images[i], labels[i])
            key = f"{i:08}"
            txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()

def store_many_hdf5(images, labels):
    """ Stores an array of images to HDF5.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "images", np.shape(images), h5py.h5t.STD_U8BE, data=images
    )
    meta_set = file.create_dataset(
        "meta", np.shape(labels), h5py.h5t.STD_U8BE, data=labels
    )
    file.close()
```

## Mempersiapkan kumpulan data



```python
cutoffs = [10, 100, 1000, 10000, 100000]

# Let's double our images so that we have 100,000
images = np.concatenate((images, images), axis=0)
labels = np.concatenate((labels, labels), axis=0)

# Make sure you actually have 100,000 images and labels
print(np.shape(images))
print(np.shape(labels))
```

    (100000, 32, 32, 3)
    (100000,)
    

## Percobaan menyimpan banyak gambar



```python
_store_many_funcs = dict(
    disk=store_many_disk, lmdb=store_many_lmdb, hdf5=store_many_hdf5
)

from timeit import timeit

store_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_store_many_funcs[method](images_, labels_)",
            setup="images_=images[:cutoff]; labels_=labels[:cutoff]",
            number=1,
            globals=globals(),
        )
        store_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, Time usage: {t}")
```

    Method: disk, Time usage: 0.006869507999908819
    Method: lmdb, Time usage: 0.006049005000022589
    Method: hdf5, Time usage: 0.0019053949999943143
    Method: disk, Time usage: 0.04307519299982232
    Method: lmdb, Time usage: 0.014659418000519508
    Method: hdf5, Time usage: 0.003004102999511815
    Method: disk, Time usage: 0.41022079000049416
    Method: lmdb, Time usage: 0.044535188000736525
    Method: hdf5, Time usage: 0.004707793000306992
    Method: disk, Time usage: 4.063132497999504
    Method: lmdb, Time usage: 0.4191534169995066
    Method: hdf5, Time usage: 0.06269118000000162
    Method: disk, Time usage: 47.31354137699964
    Method: lmdb, Time usage: 4.383981278000647
    Method: hdf5, Time usage: 0.5977927989997625
    

waktu yang di butuhkan untuk semua penyimpanan itu?


```python
import matplotlib.pyplot as plt

def plot_with_legend(
    x_range, y_data, legend_labels, x_label, y_label, title, log=False
):
    """ Displays a single plot with multiple datasets and matching legends.
        Parameters:
        --------------
        x_range         list of lists containing x data
        y_data          list of lists containing y values
        legend_labels   list of string legend labels
        x_label         x axis label
        y_label         y axis label
    """
    plt.style.use("seaborn-whitegrid")
    plt.figure(figsize=(10, 7))

    if len(y_data) != len(legend_labels):
        raise TypeError(
            "Error: number of data sets does not match number of labels."
        )

    all_plots = []
    for data, label in zip(y_data, legend_labels):
        if log:
            temp, = plt.loglog(x_range, data, label=label)
        else:
            temp, = plt.plot(x_range, data, label=label)
        all_plots.append(temp)

    plt.title(title)
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    plt.legend(handles=all_plots)
    plt.show()

# Getting the store timings data to display
disk_x = store_many_timings["disk"]
lmdb_x = store_many_timings["lmdb"]
hdf5_x = store_many_timings["hdf5"]

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Storage time",
    log=False,
)

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Log storage time",
    log=True,
)
```

    <ipython-input-71-99d89538a067>:15: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.
      plt.style.use("seaborn-whitegrid")
    


    
![png](output_37_1.png)
    


    <ipython-input-71-99d89538a067>:15: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.
      plt.style.use("seaborn-whitegrid")
    


    
![png](output_37_3.png)
    


# Membaca 1 gambar

## Membaca dari disk


```python
def read_single_disk(image_id):
    """ Stores a single image to disk.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    image = np.array(Image.open(disk_dir / f"{image_id}.png"))

    with open(disk_dir / f"{image_id}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        label = int(next(reader)[0])

    return image, label
```

## Membaca dari LMDB


```python
def read_single_lmdb(image_id):
    """ Stores a single image to LMDB.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Encode the key the same way as we stored it
        data = txn.get(f"{image_id:08}".encode("ascii"))
        # Remember it's a CIFAR_Image object that is loaded
        cifar_image = pickle.loads(data)
        # Retrieve the relevant bits
        image = cifar_image.get_image()
        label = cifar_image.label
    env.close()

    return image, label
```

## Membaca dari HDF5


```python
def read_single_hdf5(image_id):
    """ Stores a single image to HDF5.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "r+")

    image = np.array(file["/image"]).astype("uint8")
    label = int(np.array(file["/meta"]).astype("uint8"))

    return image, label
```


```python
_read_single_funcs = dict(
    disk=read_single_disk, lmdb=read_single_lmdb, hdf5=read_single_hdf5
)
```

# Percobaan membaca 1 gambar



```python
from timeit import timeit

read_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_read_single_funcs[method](0)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    read_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```

    Method: disk, Time usage: 0.005429893999462365
    Method: lmdb, Time usage: 0.004221395000058692
    Method: hdf5, Time usage: 0.007923545999801718
    

# Membaca banyak gambar

## Menyesuaikan kode untuk banyak gambar



```python
def read_many_disk(num_images):
    """ Reads image from disk.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Loop over all IDs and read each image in one by one
    for image_id in range(num_images):
        images.append(np.array(Image.open(disk_dir / f"{image_id}.png")))

    with open(disk_dir / f"{num_images}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for row in reader:
            labels.append(int(row[0]))
    return images, labels

def read_many_lmdb(num_images):
    """ Reads image from LMDB.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Read all images in one single transaction, with one lock
        # We could split this up into multiple transactions if needed
        for image_id in range(num_images):
            data = txn.get(f"{image_id:08}".encode("ascii"))
            # Remember that it's a CIFAR_Image object
            # that is stored as the value
            cifar_image = pickle.loads(data)
            # Retrieve the relevant bits
            images.append(cifar_image.get_image())
            labels.append(cifar_image.label)
    env.close()
    return images, labels

def read_many_hdf5(num_images):
    """ Reads image from HDF5.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "r+")

    images = np.array(file["/images"]).astype("uint8")
    labels = np.array(file["/meta"]).astype("uint8")

    return images, labels

_read_many_funcs = dict(
    disk=read_many_disk, lmdb=read_many_lmdb, hdf5=read_many_hdf5
)
```

## Percobaa membaca banyak gambar



```python
from timeit import timeit

read_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_read_many_funcs[method](num_images)",
            setup="num_images=cutoff",
            number=1,
            globals=globals(),
        )
        read_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, No. images: {cutoff}, Time usage: {t}")
```

    Method: disk, No. images: 10, Time usage: 0.010645597999427991
    Method: lmdb, No. images: 10, Time usage: 0.005103100000269478
    Method: hdf5, No. images: 10, Time usage: 0.002974669000650465
    Method: disk, No. images: 100, Time usage: 0.04130458700001327
    Method: lmdb, No. images: 100, Time usage: 0.00907763499981229
    Method: hdf5, No. images: 100, Time usage: 0.005937028000516875
    Method: disk, No. images: 1000, Time usage: 0.4069581570001901
    Method: lmdb, No. images: 1000, Time usage: 0.029721302000325522
    Method: hdf5, No. images: 1000, Time usage: 0.016301353000017116
    Method: disk, No. images: 10000, Time usage: 4.001311644000452
    Method: lmdb, No. images: 10000, Time usage: 0.31842470899937325
    Method: hdf5, No. images: 10000, Time usage: 0.16219747300056042
    Method: disk, No. images: 100000, Time usage: 34.85459474700019
    Method: lmdb, No. images: 100000, Time usage: 1.8565617599997495
    Method: hdf5, No. images: 100000, Time usage: 1.072509398000875
    

plot waktu baca


```python
disk_x_r = read_many_timings["disk"]
lmdb_x_r = read_many_timings["lmdb"]
hdf5_x_r = read_many_timings["hdf5"]

plot_with_legend(
    cutoffs,
    [disk_x_r, lmdb_x_r, hdf5_x_r],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to read",
    "Read time",
    log=False,
)

plot_with_legend(
    cutoffs,
    [disk_x_r, lmdb_x_r, hdf5_x_r],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to read",
    "Log read time",
    log=True,
)
```

    <ipython-input-71-99d89538a067>:15: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.
      plt.style.use("seaborn-whitegrid")
    


    
![png](output_54_1.png)
    


    <ipython-input-71-99d89538a067>:15: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.
      plt.style.use("seaborn-whitegrid")
    


    
![png](output_54_3.png)
    


plot waktu baca dan tulis


```python
plot_with_legend(
    cutoffs,
    [disk_x_r, lmdb_x_r, hdf5_x_r, disk_x, lmdb_x, hdf5_x],
    [
        "Read PNG",
        "Read LMDB",
        "Read HDF5",
        "Write PNG",
        "Write LMDB",
        "Write HDF5",
    ],
    "Number of images",
    "Seconds",
    "Log Store and Read Times",
    log=False,
)
```

    <ipython-input-71-99d89538a067>:15: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.
      plt.style.use("seaborn-whitegrid")
    


    
![png](output_56_1.png)
    


Berapa banyak ruang disk yang digunakan berbagai metode penyimpanan?


```python
# Memory used in KB
disk_mem = [24, 204, 2004, 20032, 200296]
lmdb_mem = [60, 420, 4000, 39000, 393000]
hdf5_mem = [36, 304, 2900, 29000, 293000]

X = [disk_mem, lmdb_mem, hdf5_mem]

ind = np.arange(3)
width = 0.35

plt.subplots(figsize=(8, 10))
plots = [plt.bar(ind, [row[0] for row in X], width)]
for i in range(1, len(cutoffs)):
    plots.append(
        plt.bar(
            ind, [row[i] for row in X], width, bottom=[row[i - 1] for row in X]
        )
    )

plt.ylabel("Memory in KB")
plt.title("Disk memory used by method")
plt.xticks(ind, ("PNG", "LMDB", "HDF5"))
plt.yticks(np.arange(0, 400000, 100000))

plt.legend(
    [plot[0] for plot in plots], ("10", "100", "1,000", "10,000", "100,000")
)
plt.show()
```


    
![png](output_58_0.png)
    

